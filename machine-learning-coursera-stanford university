a:=b is assignment
a=b is truth assertion

alpha is learning rate

gradient descent algorithn
-use simultaneous update
-when approaching local min, gradient descent automatically takes smaller steps even at same learning rate.

vector
nx1 matrix
usually 1-indexed (eg y1,y2,..) instead of 0-indexed (eg y0,t1,...)

no need feature scaling if using normal equation method compared to gradient descent. magnitude of feature values insignificant compared to computational cost

gradient descent vs normal equation
if number of features is small, use normal equation

applying linear regression to classification problem not a good idea:
-if have extreme values, will cause bad classification
-even if all values are 0 or 1, the threshold output can end up being not 0 or 1.

logistic regression is a classification algorithm even though name is regression.
will restrict threshold output to between 0 and 1

logistic function=sigmoid function


